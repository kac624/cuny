---
title: "D621 HW5"
author: "Keith Colella"
date: "`r Sys.Date()`"
output: html_document
---

```{r}
# Load required libraries
library(tidyverse) 
library(ggplot2) 
library(corrplot)
library(psych)
library(naniar)
library(cowplot)
library(mice)
library(pscl)
library(MASS)
library(VGAM)
```

# Data Exploration

```{r}
# Load the data
wine_data <- read.csv("wine-training-data.csv")

# Glimpse
glimpse(wine_data)
```

```{r}
# Drop index
wine_data <- wine_data %>%
  dplyr::select(-INDEX)

# Summary statistics for the dataset
summary_stats <- describe(wine_data)
print(summary_stats)
```

```{r}
# Check for missing values
missing_values <- colSums(is.na(wine_data))
print(missing_values)
```

```{r}
# Correlation matrix for numerical variables
numerical_vars <- wine_data %>% select_if(is.numeric)

# Compute the correlation matrix
correlation_matrix <- cor(numerical_vars, use = "pairwise.complete.obs")

# Plot the heatmap
corrplot(correlation_matrix, method = "color", type = "lower")
```

```{r}
# Histograms for numerical vars
histograms <- lapply(names(dplyr::select(numerical_vars, -TARGET)), function(var) {
  ggplot(wine_data, aes_string(x = var)) +
    geom_histogram()
})

# Arrange histograms in a grid
histogram_grid <- plot_grid(plotlist = histograms, ncol = 3)

# Save or display the plot grid
print(histogram_grid)
```

```{r}
# Histogram for target variable
ggplot(wine_data, aes(x = TARGET)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "white") +
  labs(title = "Distribution of TARGET (Cases Purchased)", x = "TARGET", y = "Frequency")
```

```{r}
# Missing value patterns
naniar_plot <- gg_miss_var(wine_data, show_pct = TRUE) +
  labs(title = "Missing Data Patterns", x = "Variables", y = "Number of Missing Values") +
  theme_minimal()

print(naniar_plot)

# Create a heatmap of missing values
gg_miss_upset(wine_data)
```

```{r}
nrow(wine_data)
nrow(na.omit(wine_data))

wine_data_naomit <- na.omit(wine_data)
# wine_data <- na.omit(wine_data)
```

```{r}
imputed_data <- mice(wine_data, m = 5, method = "pmm", seed = 123)
wine_data <- complete(imputed_data, action = 1)
```


```{r}
variables <- names(wine_data)[!names(wine_data) %in% c("TARGET")]

plots <- lapply(variables, function(var) {
  ggplot(wine_data, aes_string(x = var, y = "TARGET")) +
    geom_point() 
})

# Arrange the plots in a grid (5 rows x 3 columns)
grid_plot <- plot_grid(plotlist = plots, nrow = 5, ncol = 3, rel_heights = c(2,2,2,2,2))

print(grid_plot)
```

```{r}
variables <- names(wine_data)[!names(wine_data) %in% c("TARGET")]

plots <- lapply(variables, function(var) {
  ggplot(wine_data, aes_string(x = var, y = "TARGET")) +
    geom_point() 
})

plots
```


# Modeling

```{r}
# Fit a Poisson GLM with NAs omitted, as baseline
poisson_model_naomit <- glm(TARGET ~ ., family = poisson(link = "log"), data = wine_data_naomit)
summary(poisson_model_naomit)
```

```{r}
# Fit a Poisson GLM
poisson_model <- glm(TARGET ~ ., family = poisson(link = "log"), data = wine_data)
summary(poisson_model)
```

```{r}
plot(poisson_model)
```


```{r}
# Check for overdispersion
# Calculate overdispersion statistic: residual deviance / degrees of freedom
overdispersion_stat <- sum(residuals(poisson_model, type = "pearson")^2) / df.residual(poisson_model)
print(paste("Overdispersion statistic:", overdispersion_stat))
```

```{r}
# Fit a Negative Binomial regression
nb_model <- glm.nb(TARGET ~ ., data = wine_data)
summary(nb_model)
```

```{r}
plot(nb_model)
```


```{r}
# Compare models using AIC
cat("AIC of Poisson model:", AIC(poisson_model), "\n")
cat("AIC of Negative Binomial model:", AIC(nb_model), "\n")
```

```{r}
zip_model <- zeroinfl(TARGET ~ . | 1, dist = "poisson", data = wine_data)
summary(zip_model)
```

```{r}
# plot(zip_model)
```

```{r}
# Compare models using AIC
cat("AIC of Poisson model:", AIC(poisson_model), "\n")
cat("AIC of Zero-Inflated Poisson model:", AIC(zip_model), "\n")
```

```{r}
# Stepwise elimination based on p-values
p_threshold <- 0.10
feature_selection_data <- wine_data

for (i in 1:ncol(wine_data)-1) {
  # Fit model
  feature_selection_model <- glm(TARGET ~ ., family = poisson, data = feature_selection_data)
  
  # Get p-values for all predictors
  p_vals <- summary(feature_selection_model)$coefficients[, 4]
  
  # Identify the predictor with the highest p-value
  max_p <- max(p_vals[-1], na.rm = TRUE)  # Exclude intercept
  
  if (max_p < p_threshold) {
    print("STOPPING POINT!")
    break  # Stop if all predictors are significant
  }
  
  # Find the predictor with the highest p-value
  worst_predictor <- names(which.max(p_vals[-1]))
  
  # Remove the worst predictor
  feature_selection_data <- dplyr::select(
    feature_selection_data, -contains(worst_predictor)
  )
  print(paste("Removed ", worst_predictor))
}

# Final model
summary(feature_selection_model)
```

```{r}
plot(feature_selection_model)
```

```{r}
full_model <- glm(
  TARGET ~ (VolatileAcidity + Alcohol + LabelAppeal + AcidIndex + STARS)^2 + 
    I(VolatileAcidity^2) + I(Alcohol^2) + I(LabelAppeal^2) + I(AcidIndex^2) + I(STARS^2) +
    I(VolatileAcidity^3) + I(Alcohol^3) + I(LabelAppeal^3) + I(AcidIndex^3) + I(STARS^3), 
  family = poisson, data = wine_data
)

summary(full_model)
```

```{r}
overdispersion_stat <- sum(residuals(full_model, type = "pearson")^2) / df.residual(full_model)
print(paste("Overdispersion statistic:", overdispersion_stat))
```


```{r}
p_threshold <- 0.10

# Start with the full model
feature_eng_model <- glm(
  TARGET ~ (VolatileAcidity + Alcohol + LabelAppeal + AcidIndex + STARS)^2 + 
    I(VolatileAcidity^2) + I(Alcohol^2) + I(LabelAppeal^2) + I(AcidIndex^2) + I(STARS^2) +
    I(VolatileAcidity^3) + I(Alcohol^3) + I(LabelAppeal^3) + I(AcidIndex^3) + I(STARS^3), 
  family = poisson, data = wine_data
)

for (i in 1:(ncol(wine_data)-1)) {
  # Extract p-values of current model
  p_vals <- summary(feature_eng_model)$coefficients[,4]
  
  # Identify the predictor with the highest p-value (excluding the intercept)
  max_p <- max(p_vals[-1], na.rm = TRUE)
  
  # Check if we should stop (all predictors below threshold)
  if (max_p < p_threshold) {
    message("STOPPING POINT! All predictors are below the p-value threshold.")
    break
  }
  
  # Identify worst predictor by name
  predictor_names <- names(p_vals)[-1]
  worst_predictor <- predictor_names[which.max(p_vals[-1])]
  
  # Update the model by removing the worst predictor
  # . ~ . - var modifies the existing formula by dropping that variable
  feature_eng_model <- update(feature_eng_model, as.formula(paste(". ~ . -", worst_predictor)))
  
  message(paste("Removed:", worst_predictor))
}

# Final model summary
summary(feature_eng_model)
```

```{r}
plot(feature_eng_model)
```

```{r}
overdispersion_stat <- sum(residuals(feature_eng_model, type = "pearson")^2) / df.residual(feature_eng_model)
print(paste("Overdispersion statistic:", overdispersion_stat))
```

```{r}
gp_model <- vglm(
  TARGET ~ STARS + I(LabelAppeal^2) + I(AcidIndex^2) + I(STARS^2) + I(AcidIndex^3) + I(STARS^3) +
    AcidIndex:VolatileAcidity + STARS:VolatileAcidity + STARS:Alcohol + STARS:AcidIndex,
  family = genpoisson0(), data = wine_data
)

summary(gp_model)
```

```{r}
plot(gp_model)
```

```{r}
models <- list(
  poisson_model_naomit, poisson_model, nb_model, zip_model, 
  feature_selection_model, full_model, feature_eng_model, gp_model
)
maes <- c()

for (model in models) {
  predicted <- predict(model, type = "response")
  actual <- wine_data$TARGET
  if (length(predicted) < length(actual)) {
    actual <- wine_data_naomit$TARGET
  }
  mae <- mean(abs(actual - predicted))
  maes <- c(maes,mae)
}

maes
```


