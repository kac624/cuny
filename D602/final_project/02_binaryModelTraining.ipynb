{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# functional\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# custom\n",
    "from scripts.classes import RnnTextClassifier, RnnDataset\n",
    "from scripts.functions import train_rnn, rnn_bce_logits_predict\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names = [\n",
    "    'tfidf_train', 'w2v_train', 'bert_train', 'gpt_train', \n",
    "    'tfidf_test', 'w2v_test', 'bert_test', 'gpt_test', \n",
    "    'y_train', 'y_test'\n",
    "]\n",
    "\n",
    "for var_name in data_names:\n",
    "    with open(f'data/{var_name}.pkl', 'rb') as f:\n",
    "        globals()[var_name] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_int = {label: idx for idx, label in enumerate(np.unique(y_train))}\n",
    "int_to_label = {idx: label for idx, label in enumerate(np.unique(y_train))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binzarize Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'barely-true',\n",
       " 1: 'false',\n",
       " 2: 'half-true',\n",
       " 3: 'mostly-true',\n",
       " 4: 'pants-fire',\n",
       " 5: 'true'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Train---\n",
      "tensor([0.5617, 0.4383])\n",
      "---Test---\n",
      "tensor([0.5635, 0.4365])\n"
     ]
    }
   ],
   "source": [
    "false = ['false', 'pants-fire', 'barely-true']\n",
    "true = ['half-true', 'mostly-true', 'true']\n",
    "\n",
    "y_train_binary = torch.tensor(np.where(y_train.isin(false), 1, 0), dtype = torch.float)\n",
    "y_test_binary = torch.tensor(np.where(y_test.isin(false), 1, 0), dtype = torch.float)\n",
    "\n",
    "print(\n",
    "    f'---Train---\\n{y_train_binary.unique(return_counts = True)[1] / len(y_train_binary)}\\n'\n",
    "    f'---Test---\\n{y_test_binary.unique(return_counts = True)[1] / len(y_test_binary)}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/y_train_binary.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train_binary, f)\n",
    "\n",
    "with open(f'data/y_test_binary.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test_binary, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain models on binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with RNN-tfidf - Time elapsed: 0.79\n",
      "\n",
      "Finished with LR-tfidf - Time elapsed: 0.79\n",
      "\n",
      "Finished with RF-tfidf - Time elapsed: 1.41\n",
      "\n",
      "Finished with SVM-tfidf - Time elapsed: 2.17\n",
      "\n",
      "Finished with RNN-w2v - Time elapsed: 2.93\n",
      "\n",
      "Finished with LR-w2v - Time elapsed: 2.94\n",
      "\n",
      "Finished with RF-w2v - Time elapsed: 4.29\n",
      "\n",
      "Finished with SVM-w2v - Time elapsed: 5.09\n",
      "\n",
      "Finished with RNN-bert - Time elapsed: 5.80\n",
      "\n",
      "Finished with LR-bert - Time elapsed: 5.82\n",
      "\n",
      "Finished with RF-bert - Time elapsed: 7.07\n",
      "\n",
      "Finished with SVM-bert - Time elapsed: 8.58\n",
      "\n",
      "Finished with RNN-gpt - Time elapsed: 9.28\n",
      "\n",
      "Finished with LR-gpt - Time elapsed: 9.40\n",
      "\n",
      "Finished with RF-gpt - Time elapsed: 10.64\n",
      "\n",
      "Finished with SVM-gpt - Time elapsed: 12.29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "for X_train, X_name in zip([tfidf_train, w2v_train, bert_train, gpt_train], ['tfidf', 'w2v', 'bert', 'gpt']):\n",
    "\n",
    "    # recurrent neural network\n",
    "    rnn = RnnTextClassifier(\n",
    "        input_size = X_train.shape[1], output_size = 1, \n",
    "        hidden_size = 256, num_layers = 2, dropout = 0.5\n",
    "    )\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(rnn.parameters(), lr = 0.001)\n",
    "    n_epochs = range(100)\n",
    "    dataset = RnnDataset(X_train, y_train_binary.unsqueeze(1))\n",
    "    data_loader = DataLoader(dataset, batch_size = int(X_train.shape[0] / 128), shuffle = True)\n",
    "    trained_rnn = train_rnn(rnn, data_loader, criterion, optimizer, n_epochs)\n",
    "    torch.save(trained_rnn, f'models/rnn_binary_{X_name}.pth')\n",
    "    print(f'Finished with RNN-{X_name} - Time elapsed: {(time.perf_counter()-start_time)/60:.2f}\\n')\n",
    "\n",
    "    # logistic regression\n",
    "    lr = LogisticRegression(max_iter = 4000, penalty='l2', C = 0.1)\n",
    "    lr.fit(X_train, y_train_binary)\n",
    "    joblib.dump(lr, f'models/lr_binary_{X_name}.joblib')\n",
    "    print(f'Finished with LR-{X_name} - Time elapsed: {(time.perf_counter()-start_time)/60:.2f}\\n')\n",
    "\n",
    "    # random forest\n",
    "    rf = RandomForestClassifier(n_estimators = 1000, max_depth = 100, max_features = 'log2')\n",
    "    rf.fit(X_train, y_train_binary)\n",
    "    joblib.dump(rf, f'models/rf_binary_{X_name}.joblib')\n",
    "    print(f'Finished with RF-{X_name} - Time elapsed: {(time.perf_counter()-start_time)/60:.2f}\\n')\n",
    "        \n",
    "    # support vector machine\n",
    "    svm = SVC(kernel = 'linear')\n",
    "    svm.fit(X_train, y_train_binary)\n",
    "    joblib.dump(svm, f'models/svm_binary_{X_name}.joblib')\n",
    "    print(f'Finished with SVM-{X_name} - Time elapsed: {(time.perf_counter()-start_time)/60:.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tfidf = joblib.load('models/lr_binary_tfidf.joblib')\n",
    "lr_w2v = joblib.load('models/lr_binary_w2v.joblib')\n",
    "lr_bert = joblib.load('models/lr_binary_bert.joblib')\n",
    "lr_gpt = joblib.load('models/lr_binary_gpt.joblib')\n",
    "\n",
    "rf_tfidf = joblib.load('models/rf_binary_tfidf.joblib')\n",
    "rf_w2v = joblib.load('models/rf_binary_w2v.joblib')\n",
    "rf_bert = joblib.load('models/rf_binary_bert.joblib')\n",
    "rf_gpt = joblib.load('models/rf_binary_gpt.joblib')\n",
    "\n",
    "svm_tfidf = joblib.load('models/svm_binary_tfidf.joblib')\n",
    "svm_w2v = joblib.load('models/svm_binary_w2v.joblib')\n",
    "svm_bert = joblib.load('models/svm_binary_bert.joblib')\n",
    "svm_gpt = joblib.load('models/svm_binary_gpt.joblib')\n",
    "\n",
    "rnn_tfidf = torch.load('models/rnn_binary_tfidf.pth')\n",
    "rnn_w2v = torch.load('models/rnn_binary_w2v.pth')\n",
    "rnn_bert = torch.load('models/rnn_binary_bert.pth')\n",
    "rnn_gpt = torch.load('models/rnn_binary_gpt.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    rnn_tfidf, rnn_w2v, rnn_bert, rnn_gpt,\n",
    "    lr_tfidf, lr_w2v, lr_bert, lr_gpt,\n",
    "    rf_tfidf, rf_w2v, rf_bert, rf_gpt, \n",
    "    svm_tfidf, svm_w2v, svm_bert, svm_gpt\n",
    "]\n",
    "\n",
    "data_sets = [\n",
    "    (tfidf_train, tfidf_test), (w2v_train, w2v_test), \n",
    "    (bert_train, bert_test), (gpt_train, gpt_test),\n",
    "]\n",
    "\n",
    "data_names = ['tfidf', 'w2v', 'bert', 'gpt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RnnTextClassifier(\n",
      "  (rnn): RNN(1000, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Data: tfidf\n",
      "In-sample accuracy: 0.842\n",
      "Out-of-sample accuracy: 0.540\n",
      "Out-of-sample F1: 0.468\n",
      "Confusion Matrix (OOS):\n",
      "[[0.599 0.401]\n",
      " [0.537 0.463]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: RnnTextClassifier(\n",
      "  (rnn): RNN(1000, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Data: w2v\n",
      "In-sample accuracy: 0.590\n",
      "Out-of-sample accuracy: 0.595\n",
      "Out-of-sample F1: 0.438\n",
      "Confusion Matrix (OOS):\n",
      "[[0.776 0.224]\n",
      " [0.638 0.362]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: RnnTextClassifier(\n",
      "  (rnn): RNN(768, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Data: bert\n",
      "In-sample accuracy: 0.929\n",
      "Out-of-sample accuracy: 0.601\n",
      "Out-of-sample F1: 0.455\n",
      "Confusion Matrix (OOS):\n",
      "[[0.772 0.228]\n",
      " [0.618 0.382]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: RnnTextClassifier(\n",
      "  (rnn): RNN(768, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Data: gpt\n",
      "In-sample accuracy: 0.681\n",
      "Out-of-sample accuracy: 0.579\n",
      "Out-of-sample F1: 0.483\n",
      "Confusion Matrix (OOS):\n",
      "[[0.678 0.322]\n",
      " [0.55  0.45 ]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: LogisticRegression(C=0.1, max_iter=4000)\n",
      "Data: tfidf\n",
      "In-sample accuracy: 0.636\n",
      "Out-of-sample accuracy: 0.607\n",
      "Out-of-sample F1: 0.362\n",
      "Confusion Matrix (OOS):\n",
      "[[0.88  0.12 ]\n",
      " [0.745 0.255]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: LogisticRegression(C=0.1, max_iter=4000)\n",
      "Data: w2v\n",
      "In-sample accuracy: 0.589\n",
      "Out-of-sample accuracy: 0.597\n",
      "Out-of-sample F1: 0.430\n",
      "Confusion Matrix (OOS):\n",
      "[[0.789 0.211]\n",
      " [0.651 0.349]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: LogisticRegression(C=0.1, max_iter=4000)\n",
      "Data: bert\n",
      "In-sample accuracy: 0.664\n",
      "Out-of-sample accuracy: 0.621\n",
      "Out-of-sample F1: 0.462\n",
      "Confusion Matrix (OOS):\n",
      "[[0.814 0.186]\n",
      " [0.627 0.373]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: LogisticRegression(C=0.1, max_iter=4000)\n",
      "Data: gpt\n",
      "In-sample accuracy: 0.672\n",
      "Out-of-sample accuracy: 0.586\n",
      "Out-of-sample F1: 0.413\n",
      "Confusion Matrix (OOS):\n",
      "[[0.78  0.22 ]\n",
      " [0.665 0.335]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: RandomForestClassifier(max_depth=100, max_features='log2', n_estimators=1000)\n",
      "Data: tfidf\n",
      "In-sample accuracy: 0.961\n",
      "Out-of-sample accuracy: 0.595\n",
      "Out-of-sample F1: 0.384\n",
      "Confusion Matrix (OOS):\n",
      "[[0.832 0.168]\n",
      " [0.711 0.289]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: RandomForestClassifier(max_depth=100, max_features='log2', n_estimators=1000)\n",
      "Data: w2v\n",
      "In-sample accuracy: 1.000\n",
      "Out-of-sample accuracy: 0.571\n",
      "Out-of-sample F1: 0.465\n",
      "Confusion Matrix (OOS):\n",
      "[[0.683 0.317]\n",
      " [0.573 0.427]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: RandomForestClassifier(max_depth=100, max_features='log2', n_estimators=1000)\n",
      "Data: bert\n",
      "In-sample accuracy: 1.000\n",
      "Out-of-sample accuracy: 0.594\n",
      "Out-of-sample F1: 0.334\n",
      "Confusion Matrix (OOS):\n",
      "[[0.873 0.127]\n",
      " [0.767 0.233]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: RandomForestClassifier(max_depth=100, max_features='log2', n_estimators=1000)\n",
      "Data: gpt\n",
      "In-sample accuracy: 1.000\n",
      "Out-of-sample accuracy: 0.581\n",
      "Out-of-sample F1: 0.272\n",
      "Confusion Matrix (OOS):\n",
      "[[0.892 0.108]\n",
      " [0.821 0.179]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: SVC(kernel='linear')\n",
      "Data: tfidf\n",
      "In-sample accuracy: 0.671\n",
      "Out-of-sample accuracy: 0.605\n",
      "Out-of-sample F1: 0.489\n",
      "Confusion Matrix (OOS):\n",
      "[[0.737 0.263]\n",
      " [0.566 0.434]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: SVC(kernel='linear')\n",
      "Data: w2v\n",
      "In-sample accuracy: 0.571\n",
      "Out-of-sample accuracy: 0.576\n",
      "Out-of-sample F1: 0.141\n",
      "Confusion Matrix (OOS):\n",
      "[[0.961 0.039]\n",
      " [0.92  0.08 ]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: SVC(kernel='linear')\n",
      "Data: bert\n",
      "In-sample accuracy: 0.677\n",
      "Out-of-sample accuracy: 0.614\n",
      "Out-of-sample F1: 0.470\n",
      "Confusion Matrix (OOS):\n",
      "[[0.786 0.214]\n",
      " [0.608 0.392]]\n",
      "\n",
      "----------\n",
      "\n",
      "Model: SVC(kernel='linear')\n",
      "Data: gpt\n",
      "In-sample accuracy: 0.685\n",
      "Out-of-sample accuracy: 0.562\n",
      "Out-of-sample F1: 0.414\n",
      "Confusion Matrix (OOS):\n",
      "[[0.723 0.277]\n",
      " [0.646 0.354]]\n",
      "\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['model', 'data', 'accuracy_is', 'accuracy_oos', 'precision_oos', 'recall_oos', 'f1_oos']\n",
    "\n",
    "results = pd.DataFrame(columns = columns)\n",
    "\n",
    "for model, data, data_name in zip(models, data_sets*4, data_names*4):\n",
    "    X_train, X_test = data\n",
    "    if 'Rnn' in str(model):\n",
    "        y_pred_train = rnn_bce_logits_predict(model, X_train)\n",
    "        y_pred_test = rnn_bce_logits_predict(model, X_test)\n",
    "    else:\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "    accuracy_train = accuracy_score(y_train_binary, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test_binary, y_pred_test)\n",
    "    precision_oos = precision_score(y_test_binary, y_pred_test)\n",
    "    recall_oos = recall_score(y_test_binary, y_pred_test)\n",
    "    f1_oos = f1_score(y_test_binary, y_pred_test)\n",
    "    confusion_oos = confusion_matrix(y_test_binary, y_pred_test, normalize=\"true\")\n",
    "\n",
    "    result = dict(zip(columns, [\n",
    "        str(model), data_name, accuracy_train, accuracy_test, \n",
    "        precision_oos, recall_oos, f1_oos\n",
    "    ]))\n",
    "    results = pd.concat([results, pd.DataFrame(result, index=[0])], ignore_index=True)\n",
    "\n",
    "    print(\n",
    "        f'Model: {model}\\n'\n",
    "        f'Data: {data_name}\\n'\n",
    "        f'In-sample accuracy: {accuracy_train:.3f}\\n'\n",
    "        f'Out-of-sample accuracy: {accuracy_test:.3f}\\n'\n",
    "        f'Out-of-sample F1: {f1_oos:.3f}\\n'\n",
    "        f'Confusion Matrix (OOS):\\n{np.round(confusion_oos, 3)}\\n'\n",
    "        f'\\n----------\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data</th>\n",
       "      <th>accuracy_is</th>\n",
       "      <th>accuracy_oos</th>\n",
       "      <th>precision_oos</th>\n",
       "      <th>recall_oos</th>\n",
       "      <th>f1_oos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RnnTextClassifier(\\n  (rnn): RNN(1000, 256, nu...</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.842480</td>\n",
       "      <td>0.539858</td>\n",
       "      <td>0.472325</td>\n",
       "      <td>0.462929</td>\n",
       "      <td>0.467580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RnnTextClassifier(\\n  (rnn): RNN(1000, 256, nu...</td>\n",
       "      <td>w2v</td>\n",
       "      <td>0.590332</td>\n",
       "      <td>0.595107</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.361664</td>\n",
       "      <td>0.438116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RnnTextClassifier(\\n  (rnn): RNN(768, 256, num...</td>\n",
       "      <td>bert</td>\n",
       "      <td>0.929199</td>\n",
       "      <td>0.601421</td>\n",
       "      <td>0.564171</td>\n",
       "      <td>0.381555</td>\n",
       "      <td>0.455232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RnnTextClassifier(\\n  (rnn): RNN(768, 256, num...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>0.680957</td>\n",
       "      <td>0.578532</td>\n",
       "      <td>0.519833</td>\n",
       "      <td>0.450271</td>\n",
       "      <td>0.482558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=4000)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.635645</td>\n",
       "      <td>0.606946</td>\n",
       "      <td>0.621145</td>\n",
       "      <td>0.254973</td>\n",
       "      <td>0.361538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=4000)</td>\n",
       "      <td>w2v</td>\n",
       "      <td>0.588574</td>\n",
       "      <td>0.596685</td>\n",
       "      <td>0.561047</td>\n",
       "      <td>0.349005</td>\n",
       "      <td>0.430323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=4000)</td>\n",
       "      <td>bert</td>\n",
       "      <td>0.663965</td>\n",
       "      <td>0.621152</td>\n",
       "      <td>0.607670</td>\n",
       "      <td>0.372514</td>\n",
       "      <td>0.461883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=4000)</td>\n",
       "      <td>gpt</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.585635</td>\n",
       "      <td>0.540936</td>\n",
       "      <td>0.334539</td>\n",
       "      <td>0.413408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier(max_depth=100, max_feat...</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.960547</td>\n",
       "      <td>0.595107</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.289331</td>\n",
       "      <td>0.384154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestClassifier(max_depth=100, max_feat...</td>\n",
       "      <td>w2v</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.510823</td>\n",
       "      <td>0.426763</td>\n",
       "      <td>0.465025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier(max_depth=100, max_feat...</td>\n",
       "      <td>bert</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.593528</td>\n",
       "      <td>0.586364</td>\n",
       "      <td>0.233273</td>\n",
       "      <td>0.333765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestClassifier(max_depth=100, max_feat...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.580900</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.179024</td>\n",
       "      <td>0.271605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC(kernel='linear')</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.604578</td>\n",
       "      <td>0.560748</td>\n",
       "      <td>0.433996</td>\n",
       "      <td>0.489297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC(kernel='linear')</td>\n",
       "      <td>w2v</td>\n",
       "      <td>0.570508</td>\n",
       "      <td>0.576164</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.079566</td>\n",
       "      <td>0.140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC(kernel='linear')</td>\n",
       "      <td>bert</td>\n",
       "      <td>0.677344</td>\n",
       "      <td>0.614049</td>\n",
       "      <td>0.586486</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.470206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC(kernel='linear')</td>\n",
       "      <td>gpt</td>\n",
       "      <td>0.685352</td>\n",
       "      <td>0.561957</td>\n",
       "      <td>0.497462</td>\n",
       "      <td>0.354430</td>\n",
       "      <td>0.413939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model   data  accuracy_is  \\\n",
       "0   RnnTextClassifier(\\n  (rnn): RNN(1000, 256, nu...  tfidf     0.842480   \n",
       "1   RnnTextClassifier(\\n  (rnn): RNN(1000, 256, nu...    w2v     0.590332   \n",
       "2   RnnTextClassifier(\\n  (rnn): RNN(768, 256, num...   bert     0.929199   \n",
       "3   RnnTextClassifier(\\n  (rnn): RNN(768, 256, num...    gpt     0.680957   \n",
       "4            LogisticRegression(C=0.1, max_iter=4000)  tfidf     0.635645   \n",
       "5            LogisticRegression(C=0.1, max_iter=4000)    w2v     0.588574   \n",
       "6            LogisticRegression(C=0.1, max_iter=4000)   bert     0.663965   \n",
       "7            LogisticRegression(C=0.1, max_iter=4000)    gpt     0.671875   \n",
       "8   RandomForestClassifier(max_depth=100, max_feat...  tfidf     0.960547   \n",
       "9   RandomForestClassifier(max_depth=100, max_feat...    w2v     0.999609   \n",
       "10  RandomForestClassifier(max_depth=100, max_feat...   bert     0.999609   \n",
       "11  RandomForestClassifier(max_depth=100, max_feat...    gpt     0.999609   \n",
       "12                               SVC(kernel='linear')  tfidf     0.671289   \n",
       "13                               SVC(kernel='linear')    w2v     0.570508   \n",
       "14                               SVC(kernel='linear')   bert     0.677344   \n",
       "15                               SVC(kernel='linear')    gpt     0.685352   \n",
       "\n",
       "    accuracy_oos  precision_oos  recall_oos    f1_oos  \n",
       "0       0.539858       0.472325    0.462929  0.467580  \n",
       "1       0.595107       0.555556    0.361664  0.438116  \n",
       "2       0.601421       0.564171    0.381555  0.455232  \n",
       "3       0.578532       0.519833    0.450271  0.482558  \n",
       "4       0.606946       0.621145    0.254973  0.361538  \n",
       "5       0.596685       0.561047    0.349005  0.430323  \n",
       "6       0.621152       0.607670    0.372514  0.461883  \n",
       "7       0.585635       0.540936    0.334539  0.413408  \n",
       "8       0.595107       0.571429    0.289331  0.384154  \n",
       "9       0.571429       0.510823    0.426763  0.465025  \n",
       "10      0.593528       0.586364    0.233273  0.333765  \n",
       "11      0.580900       0.562500    0.179024  0.271605  \n",
       "12      0.604578       0.560748    0.433996  0.489297  \n",
       "13      0.576164       0.611111    0.079566  0.140800  \n",
       "14      0.614049       0.586486    0.392405  0.470206  \n",
       "15      0.561957       0.497462    0.354430  0.413939  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuny",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
