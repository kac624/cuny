{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# core\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# nlp processing / cleaning\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "# vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import BertTokenizer, BertModel, GPT2Tokenizer, GPT2Model\n",
    "\n",
    "# modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# functional\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# custom\n",
    "from scripts.classes import RnnTextClassifier, RnnDataset\n",
    "from scripts.functions import get_sentence_vector, get_embeddings_bert, get_embeddings_gpt, train_rnn\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data & Clean (lemmitize, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/liars_train.csv')\n",
    "test = pd.read_csv('data/liars_test.csv')\n",
    "valid = pd.read_csv('data/liars_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "train.statement = train.statement.apply(lambda x: ' '.join([token.lemma_.lower() for token in nlp(x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering - TF-IDF, Word2Vec, BERT/GPT Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10240, 1000]) torch.Size([1267, 1000])\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = 'english', ngram_range = (1,2), max_features = 1000)\n",
    "tfidf_train = tfidf.fit_transform(train.statement)\n",
    "tfidf_test = tfidf.transform(test.statement)\n",
    "\n",
    "tfidf_train = torch.tensor(tfidf_train.toarray(), dtype = torch.float)\n",
    "tfidf_test = torch.tensor(tfidf_test.toarray(), dtype = torch.float)\n",
    "\n",
    "print(tfidf_train.shape, tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Keith\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "nltk.download('punkt')\n",
    "\n",
    "tokenized_statements_train = [nltk.tokenize.word_tokenize(statement.lower()) for statement in train.statement]\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences = tokenized_statements_train, \n",
    "    vector_size = 1000, window = 5, min_count = 1, workers = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_train = pd.Series(tokenized_statements_train).apply(lambda x: get_sentence_vector(x, w2v_model))\n",
    "w2v_train = np.array(w2v_train.tolist())\n",
    "w2v_train = torch.tensor(w2v_train, dtype = torch.float)\n",
    "\n",
    "tokenized_statements_test = [nltk.tokenize.word_tokenize(statement.lower()) for statement in test.statement]\n",
    "w2v_test = pd.Series(tokenized_statements_test).apply(lambda x: get_sentence_vector(x, w2v_model))\n",
    "w2v_test = np.array(w2v_test.tolist())\n",
    "w2v_test = torch.tensor(w2v_test, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10240, 1000]) torch.Size([1267, 1000])\n"
     ]
    }
   ],
   "source": [
    "print(w2v_train.shape, w2v_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10240, 768]) torch.Size([1267, 768])\n"
     ]
    }
   ],
   "source": [
    "bert_train = train.statement.apply(lambda x: get_embeddings_bert(x, tokenizer, model))\n",
    "bert_test = test.statement.apply(lambda x: get_embeddings_bert(x, tokenizer, model))\n",
    "\n",
    "bert_train = np.array(bert_train.tolist())\n",
    "bert_test = np.array(bert_test.tolist())\n",
    "\n",
    "bert_train = torch.tensor(bert_train, dtype = torch.float)\n",
    "bert_test = torch.tensor(bert_test, dtype = torch.float)\n",
    "\n",
    "print(bert_train.shape, bert_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10240, 768]) torch.Size([1267, 768])\n"
     ]
    }
   ],
   "source": [
    "gpt_train = train.statement.apply(lambda x: get_embeddings_gpt(x, tokenizer, model))\n",
    "gpt_test = test.statement.apply(lambda x: get_embeddings_gpt(x, tokenizer, model))\n",
    "\n",
    "gpt_train = np.array(gpt_train.tolist())\n",
    "gpt_test = np.array(gpt_test.tolist())\n",
    "\n",
    "gpt_train = torch.tensor(gpt_train, dtype = torch.float)\n",
    "gpt_test = torch.tensor(gpt_test, dtype = torch.float)\n",
    "\n",
    "print(gpt_train.shape, gpt_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.label\n",
    "y_test = test.label\n",
    "\n",
    "# Create conversion dicts\n",
    "label_to_int = {label: idx for idx, label in enumerate(np.unique(y_train))}\n",
    "int_to_label = {idx: label for idx, label in enumerate(np.unique(y_train))}\n",
    "\n",
    "# Make tensors for NN\n",
    "y_train_tensor = np.array([label_to_int[label] for label in y_train])\n",
    "y_train_tensor = torch.tensor(y_train_tensor, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [tfidf_train, w2v_train, bert_train, gpt_train, tfidf_test, w2v_test, bert_test, gpt_test, y_train, y_test]\n",
    "data_names = ['tfidf_train', 'w2v_train', 'bert_train', 'gpt_train', 'tfidf_test', 'w2v_test', 'bert_test', 'gpt_test', 'y_train', 'y_test']\n",
    "\n",
    "for var_df, var_name in zip(data_list, data_names):\n",
    "    with open(f'data/{var_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(var_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with RNN-tfidf - Time elapsed: 0.56\n",
      "\n",
      "Finished with LR-tfidf - Time elapsed: 0.57\n",
      "\n",
      "Finished with RF-tfidf - Time elapsed: 0.73\n",
      "\n",
      "Finished with SVM-tfidf - Time elapsed: 1.62\n",
      "\n",
      "Finished with RNN-w2v - Time elapsed: 2.18\n",
      "\n",
      "Finished with LR-w2v - Time elapsed: 2.22\n",
      "\n",
      "Finished with RF-w2v - Time elapsed: 2.70\n",
      "\n",
      "Finished with SVM-w2v - Time elapsed: 3.58\n",
      "\n",
      "Finished with RNN-bert - Time elapsed: 4.11\n",
      "\n",
      "Finished with LR-bert - Time elapsed: 4.20\n",
      "\n",
      "Finished with RF-bert - Time elapsed: 4.57\n",
      "\n",
      "Finished with SVM-bert - Time elapsed: 5.17\n",
      "\n",
      "Finished with RNN-gpt - Time elapsed: 5.71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with LR-gpt - Time elapsed: 6.00\n",
      "\n",
      "Finished with RF-gpt - Time elapsed: 6.37\n",
      "\n",
      "Finished with SVM-gpt - Time elapsed: 7.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "for X_train, X_name in zip([tfidf_train, w2v_train, bert_train, gpt_train], ['tfidf', 'w2v', 'bert', 'gpt']):\n",
    "\n",
    "    # recurrent neural network\n",
    "    rnn = RnnTextClassifier(\n",
    "        input_size = X_train.shape[1], output_size = len(y_train.unique()), \n",
    "        hidden_size = 256, num_layers = 2\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(rnn.parameters(), lr = 0.001)\n",
    "    n_epochs = range(100)\n",
    "    dataset = RnnDataset(X_train, y_train_tensor)\n",
    "    data_loader = DataLoader(dataset, batch_size = int(X_train.shape[0] / 128), shuffle = True)\n",
    "    trained_rnn = train_rnn(rnn, data_loader, criterion, optimizer, n_epochs)\n",
    "    torch.save(trained_rnn, f'models/rnn_multi_{X_name}.pth')\n",
    "    print(f'Finished with RNN-{X_name} - Time elapsed: {(time.perf_counter()-start_time)/60:.2f}\\n')\n",
    "\n",
    "    # logistic regression\n",
    "    lr = LogisticRegression(max_iter = 4000)\n",
    "    lr.fit(X_train, y_train)\n",
    "    joblib.dump(lr, f'models/lr_multi_{X_name}.joblib')\n",
    "    print(f'Finished with LR-{X_name} - Time elapsed: {(time.perf_counter()-start_time)/60:.2f}\\n')\n",
    "\n",
    "    # random forest\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "    joblib.dump(rf, f'models/rf_multi_{X_name}.joblib')\n",
    "    print(f'Finished with RF-{X_name} - Time elapsed: {(time.perf_counter()-start_time)/60:.2f}\\n')\n",
    "        \n",
    "    # support vector machine\n",
    "    svm = SVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    joblib.dump(svm, f'models/svm_multi_{X_name}.joblib')\n",
    "    print(f'Finished with SVM-{X_name} - Time elapsed: {(time.perf_counter()-start_time)/60:.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tfidf = joblib.load('models/lr_multi_tfidf.joblib')\n",
    "lr_w2v = joblib.load('models/lr_multi_w2v.joblib')\n",
    "lr_bert = joblib.load('models/lr_multi_bert.joblib')\n",
    "lr_gpt = joblib.load('models/lr_multi_gpt.joblib')\n",
    "\n",
    "rf_tfidf = joblib.load('models/rf_multi_tfidf.joblib')\n",
    "rf_w2v = joblib.load('models/rf_multi_w2v.joblib')\n",
    "rf_bert = joblib.load('models/rf_multi_bert.joblib')\n",
    "rf_gpt = joblib.load('models/rf_multi_gpt.joblib')\n",
    "\n",
    "svm_tfidf = joblib.load('models/svm_multi_tfidf.joblib')\n",
    "svm_w2v = joblib.load('models/svm_multi_w2v.joblib')\n",
    "svm_bert = joblib.load('models/svm_multi_bert.joblib')\n",
    "svm_gpt = joblib.load('models/svm_multi_gpt.joblib')\n",
    "\n",
    "rnn_tfidf = torch.load('models/rnn_multi_tfidf.pth')\n",
    "rnn_w2v = torch.load('models/rnn_multi_w2v.pth')\n",
    "rnn_bert = torch.load('models/rnn_multi_bert.pth')\n",
    "rnn_gpt = torch.load('models/rnn_multi_gpt.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    rnn_tfidf, rnn_w2v, rnn_bert, rnn_gpt,\n",
    "    lr_tfidf, lr_w2v, lr_bert, lr_gpt,\n",
    "    rf_tfidf, rf_w2v, rf_bert, rf_gpt, \n",
    "    svm_tfidf, svm_w2v, svm_bert, svm_gpt\n",
    "]\n",
    "\n",
    "data_sets = [\n",
    "    (tfidf_train, tfidf_test), (w2v_train, w2v_test), \n",
    "    (bert_train, bert_test), (gpt_train, gpt_test),\n",
    "]\n",
    "\n",
    "data_names = ['tfidf', 'w2v', 'bert', 'gpt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RnnTextClassifier(\n",
      "  (rnn): RNN(1000, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=6, bias=True)\n",
      ")\n",
      "Data: tfidf\n",
      "In-sample accuracy: 0.986\n",
      "Out-of-sample accuracy: 0.194\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.26      0.23      0.24       212\n",
      "       false       0.19      0.18      0.19       249\n",
      "   half-true       0.21      0.21      0.21       265\n",
      " mostly-true       0.17      0.16      0.16       241\n",
      "  pants-fire       0.11      0.12      0.11        92\n",
      "        true       0.20      0.23      0.21       208\n",
      "\n",
      "    accuracy                           0.19      1267\n",
      "   macro avg       0.19      0.19      0.19      1267\n",
      "weighted avg       0.20      0.19      0.19      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "Model: RnnTextClassifier(\n",
      "  (rnn): RNN(1000, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=6, bias=True)\n",
      ")\n",
      "Data: w2v\n",
      "In-sample accuracy: 0.237\n",
      "Out-of-sample accuracy: 0.239\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.22      0.19      0.20       212\n",
      "       false       0.24      0.31      0.27       249\n",
      "   half-true       0.27      0.03      0.06       265\n",
      " mostly-true       0.25      0.72      0.37       241\n",
      "  pants-fire       0.10      0.03      0.05        92\n",
      "        true       0.00      0.00      0.00       208\n",
      "\n",
      "    accuracy                           0.24      1267\n",
      "   macro avg       0.18      0.21      0.16      1267\n",
      "weighted avg       0.20      0.24      0.17      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "Model: RnnTextClassifier(\n",
      "  (rnn): RNN(768, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=6, bias=True)\n",
      ")\n",
      "Data: bert\n",
      "In-sample accuracy: 0.999\n",
      "Out-of-sample accuracy: 0.230\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.21      0.17      0.18       212\n",
      "       false       0.25      0.22      0.23       249\n",
      "   half-true       0.27      0.28      0.27       265\n",
      " mostly-true       0.22      0.28      0.25       241\n",
      "  pants-fire       0.17      0.21      0.19        92\n",
      "        true       0.22      0.21      0.21       208\n",
      "\n",
      "    accuracy                           0.23      1267\n",
      "   macro avg       0.22      0.22      0.22      1267\n",
      "weighted avg       0.23      0.23      0.23      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "Model: RnnTextClassifier(\n",
      "  (rnn): RNN(768, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=6, bias=True)\n",
      ")\n",
      "Data: gpt\n",
      "In-sample accuracy: 0.857\n",
      "Out-of-sample accuracy: 0.210\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.16      0.06      0.08       212\n",
      "       false       0.22      0.28      0.24       249\n",
      "   half-true       0.20      0.34      0.25       265\n",
      " mostly-true       0.24      0.13      0.17       241\n",
      "  pants-fire       0.08      0.03      0.05        92\n",
      "        true       0.23      0.29      0.26       208\n",
      "\n",
      "    accuracy                           0.21      1267\n",
      "   macro avg       0.19      0.19      0.18      1267\n",
      "weighted avg       0.20      0.21      0.19      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression(max_iter=4000)\n",
      "Data: tfidf\n",
      "In-sample accuracy: 0.400\n",
      "Out-of-sample accuracy: 0.239\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.27      0.18      0.22       212\n",
      "       false       0.27      0.36      0.31       249\n",
      "   half-true       0.24      0.28      0.26       265\n",
      " mostly-true       0.22      0.21      0.21       241\n",
      "  pants-fire       0.10      0.03      0.05        92\n",
      "        true       0.21      0.23      0.22       208\n",
      "\n",
      "    accuracy                           0.24      1267\n",
      "   macro avg       0.22      0.21      0.21      1267\n",
      "weighted avg       0.23      0.24      0.23      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "Model: LogisticRegression(max_iter=4000)\n",
      "Data: w2v\n",
      "In-sample accuracy: 0.239\n",
      "Out-of-sample accuracy: 0.220\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.15      0.05      0.08       212\n",
      "       false       0.22      0.43      0.29       249\n",
      "   half-true       0.21      0.29      0.24       265\n",
      " mostly-true       0.27      0.33      0.30       241\n",
      "  pants-fire       0.11      0.01      0.02        92\n",
      "        true       0.14      0.02      0.04       208\n",
      "\n",
      "    accuracy                           0.22      1267\n",
      "   macro avg       0.18      0.19      0.16      1267\n",
      "weighted avg       0.19      0.22      0.18      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "Model: LogisticRegression(max_iter=4000)\n",
      "Data: bert\n",
      "In-sample accuracy: 0.406\n",
      "Out-of-sample accuracy: 0.260\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.25      0.20      0.23       212\n",
      "       false       0.28      0.23      0.25       249\n",
      "   half-true       0.29      0.32      0.30       265\n",
      " mostly-true       0.24      0.33      0.28       241\n",
      "  pants-fire       0.27      0.26      0.27        92\n",
      "        true       0.22      0.21      0.21       208\n",
      "\n",
      "    accuracy                           0.26      1267\n",
      "   macro avg       0.26      0.26      0.26      1267\n",
      "weighted avg       0.26      0.26      0.26      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "Model: LogisticRegression(max_iter=4000)\n",
      "Data: gpt\n",
      "In-sample accuracy: 0.400\n",
      "Out-of-sample accuracy: 0.228\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.20      0.10      0.13       212\n",
      "       false       0.24      0.26      0.25       249\n",
      "   half-true       0.23      0.32      0.27       265\n",
      " mostly-true       0.22      0.27      0.24       241\n",
      "  pants-fire       0.21      0.09      0.12        92\n",
      "        true       0.24      0.22      0.23       208\n",
      "\n",
      "    accuracy                           0.23      1267\n",
      "   macro avg       0.22      0.21      0.21      1267\n",
      "weighted avg       0.23      0.23      0.22      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "Model: RandomForestClassifier()\n",
      "Data: tfidf\n",
      "In-sample accuracy: 0.991\n",
      "Out-of-sample accuracy: 0.222\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.24      0.13      0.17       212\n",
      "       false       0.23      0.33      0.27       249\n",
      "   half-true       0.25      0.23      0.24       265\n",
      " mostly-true       0.21      0.26      0.23       241\n",
      "  pants-fire       0.12      0.08      0.09        92\n",
      "        true       0.20      0.18      0.19       208\n",
      "\n",
      "    accuracy                           0.22      1267\n",
      "   macro avg       0.21      0.20      0.20      1267\n",
      "weighted avg       0.22      0.22      0.22      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "Model: RandomForestClassifier()\n",
      "Data: w2v\n",
      "In-sample accuracy: 0.999\n",
      "Out-of-sample accuracy: 0.235\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.20      0.17      0.19       212\n",
      "       false       0.25      0.36      0.30       249\n",
      "   half-true       0.24      0.27      0.25       265\n",
      " mostly-true       0.26      0.26      0.26       241\n",
      "  pants-fire       0.11      0.04      0.06        92\n",
      "        true       0.22      0.17      0.19       208\n",
      "\n",
      "    accuracy                           0.24      1267\n",
      "   macro avg       0.21      0.21      0.21      1267\n",
      "weighted avg       0.23      0.24      0.23      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "Model: RandomForestClassifier()\n",
      "Data: bert\n",
      "In-sample accuracy: 0.999\n",
      "Out-of-sample accuracy: 0.210\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.20      0.11      0.14       212\n",
      "       false       0.21      0.29      0.25       249\n",
      "   half-true       0.20      0.28      0.23       265\n",
      " mostly-true       0.23      0.31      0.26       241\n",
      "  pants-fire       0.00      0.00      0.00        92\n",
      "        true       0.20      0.10      0.13       208\n",
      "\n",
      "    accuracy                           0.21      1267\n",
      "   macro avg       0.17      0.18      0.17      1267\n",
      "weighted avg       0.19      0.21      0.19      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier()\n",
      "Data: gpt\n",
      "In-sample accuracy: 0.999\n",
      "Out-of-sample accuracy: 0.242\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.18      0.06      0.09       212\n",
      "       false       0.22      0.34      0.27       249\n",
      "   half-true       0.26      0.36      0.30       265\n",
      " mostly-true       0.27      0.34      0.30       241\n",
      "  pants-fire       0.00      0.00      0.00        92\n",
      "        true       0.22      0.16      0.18       208\n",
      "\n",
      "    accuracy                           0.24      1267\n",
      "   macro avg       0.19      0.21      0.19      1267\n",
      "weighted avg       0.22      0.24      0.22      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "Model: SVC()\n",
      "Data: tfidf\n",
      "In-sample accuracy: 0.767\n",
      "Out-of-sample accuracy: 0.232\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.26      0.12      0.16       212\n",
      "       false       0.26      0.40      0.32       249\n",
      "   half-true       0.23      0.30      0.26       265\n",
      " mostly-true       0.22      0.25      0.23       241\n",
      "  pants-fire       0.33      0.01      0.02        92\n",
      "        true       0.17      0.14      0.16       208\n",
      "\n",
      "    accuracy                           0.23      1267\n",
      "   macro avg       0.25      0.20      0.19      1267\n",
      "weighted avg       0.24      0.23      0.21      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVC()\n",
      "Data: w2v\n",
      "In-sample accuracy: 0.236\n",
      "Out-of-sample accuracy: 0.250\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.00      0.00      0.00       212\n",
      "       false       0.23      0.50      0.32       249\n",
      "   half-true       0.23      0.40      0.29       265\n",
      " mostly-true       0.33      0.36      0.34       241\n",
      "  pants-fire       0.00      0.00      0.00        92\n",
      "        true       0.00      0.00      0.00       208\n",
      "\n",
      "    accuracy                           0.25      1267\n",
      "   macro avg       0.13      0.21      0.16      1267\n",
      "weighted avg       0.16      0.25      0.19      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVC()\n",
      "Data: bert\n",
      "In-sample accuracy: 0.402\n",
      "Out-of-sample accuracy: 0.260\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.30      0.11      0.16       212\n",
      "       false       0.27      0.36      0.31       249\n",
      "   half-true       0.25      0.41      0.31       265\n",
      " mostly-true       0.24      0.30      0.27       241\n",
      "  pants-fire       0.00      0.00      0.00        92\n",
      "        true       0.29      0.17      0.21       208\n",
      "\n",
      "    accuracy                           0.26      1267\n",
      "   macro avg       0.23      0.22      0.21      1267\n",
      "weighted avg       0.25      0.26      0.24      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "Model: SVC()\n",
      "Data: gpt\n",
      "In-sample accuracy: 0.221\n",
      "Out-of-sample accuracy: 0.213\n",
      "Classification report (OOS):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.00      0.00      0.00       212\n",
      "       false       0.24      0.22      0.23       249\n",
      "   half-true       0.21      0.82      0.33       265\n",
      " mostly-true       0.00      0.00      0.00       241\n",
      "  pants-fire       0.00      0.00      0.00        92\n",
      "        true       0.00      0.00      0.00       208\n",
      "\n",
      "    accuracy                           0.21      1267\n",
      "   macro avg       0.07      0.17      0.09      1267\n",
      "weighted avg       0.09      0.21      0.11      1267\n",
      "\n",
      "\n",
      "----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Keith\\miniconda3\\envs\\cuny\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "columns = ['model', 'data', 'accuracy_is', 'accuracy_oos', 'precision_oos', 'recall_oos', 'f1_oos']\n",
    "\n",
    "results = pd.DataFrame(columns = columns)\n",
    "\n",
    "for model, data, data_name in zip(models, data_sets*4, data_names*4):\n",
    "    X_train, X_test = data\n",
    "    if 'Rnn' in str(model):\n",
    "        y_pred_train = model(X_train).argmax(dim=1)\n",
    "        y_pred_train = [int_to_label[idx.item()] for idx in y_pred_train]\n",
    "        y_pred_test = model(X_test).argmax(dim=1)\n",
    "        y_pred_test = [int_to_label[idx.item()] for idx in y_pred_test]\n",
    "    else:\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    precision_oos = precision_score(y_test, y_pred_test, average='weighted')\n",
    "    recall_oos = recall_score(y_test, y_pred_test, average='weighted')\n",
    "    f1_oos = f1_score(y_test, y_pred_test, average='weighted')\n",
    "    class_report_oos = classification_report(y_test, y_pred_test)\n",
    "\n",
    "    result = dict(zip(columns, [\n",
    "        str(model), data_name, accuracy_train, accuracy_test, \n",
    "        precision_oos, recall_oos, f1_oos\n",
    "    ]))\n",
    "    results = pd.concat([results, pd.DataFrame(result, index=[0])], ignore_index=True)\n",
    "    \n",
    "    print(\n",
    "        f'Model: {model}\\n'\n",
    "        f'Data: {data_name}\\n'\n",
    "        f'In-sample accuracy: {accuracy_train:.3f}\\n'\n",
    "        f'Out-of-sample accuracy: {accuracy_test:.3f}\\n'\n",
    "        f'Classification report (OOS):\\n{class_report_oos}\\n'\n",
    "        f'\\n----------\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data</th>\n",
       "      <th>accuracy_is</th>\n",
       "      <th>accuracy_oos</th>\n",
       "      <th>precision_oos</th>\n",
       "      <th>recall_oos</th>\n",
       "      <th>f1_oos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RnnTextClassifier(\\n  (rnn): RNN(1000, 256, nu...</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.985938</td>\n",
       "      <td>0.194159</td>\n",
       "      <td>0.196119</td>\n",
       "      <td>0.194159</td>\n",
       "      <td>0.194749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RnnTextClassifier(\\n  (rnn): RNN(1000, 256, nu...</td>\n",
       "      <td>w2v</td>\n",
       "      <td>0.237012</td>\n",
       "      <td>0.239148</td>\n",
       "      <td>0.195117</td>\n",
       "      <td>0.239148</td>\n",
       "      <td>0.173715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RnnTextClassifier(\\n  (rnn): RNN(768, 256, num...</td>\n",
       "      <td>bert</td>\n",
       "      <td>0.999414</td>\n",
       "      <td>0.229676</td>\n",
       "      <td>0.230131</td>\n",
       "      <td>0.229676</td>\n",
       "      <td>0.228597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RnnTextClassifier(\\n  (rnn): RNN(768, 256, num...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>0.856934</td>\n",
       "      <td>0.209945</td>\n",
       "      <td>0.201538</td>\n",
       "      <td>0.209945</td>\n",
       "      <td>0.192728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(max_iter=4000)</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.399902</td>\n",
       "      <td>0.239148</td>\n",
       "      <td>0.232249</td>\n",
       "      <td>0.239148</td>\n",
       "      <td>0.231159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(max_iter=4000)</td>\n",
       "      <td>w2v</td>\n",
       "      <td>0.239258</td>\n",
       "      <td>0.220205</td>\n",
       "      <td>0.193823</td>\n",
       "      <td>0.220205</td>\n",
       "      <td>0.184905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(max_iter=4000)</td>\n",
       "      <td>bert</td>\n",
       "      <td>0.405957</td>\n",
       "      <td>0.260458</td>\n",
       "      <td>0.261260</td>\n",
       "      <td>0.260458</td>\n",
       "      <td>0.258416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(max_iter=4000)</td>\n",
       "      <td>gpt</td>\n",
       "      <td>0.400098</td>\n",
       "      <td>0.228098</td>\n",
       "      <td>0.225181</td>\n",
       "      <td>0.228098</td>\n",
       "      <td>0.219562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.991211</td>\n",
       "      <td>0.221784</td>\n",
       "      <td>0.220277</td>\n",
       "      <td>0.221784</td>\n",
       "      <td>0.215404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>w2v</td>\n",
       "      <td>0.999414</td>\n",
       "      <td>0.235201</td>\n",
       "      <td>0.226790</td>\n",
       "      <td>0.235201</td>\n",
       "      <td>0.227268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>bert</td>\n",
       "      <td>0.999414</td>\n",
       "      <td>0.209945</td>\n",
       "      <td>0.193252</td>\n",
       "      <td>0.209945</td>\n",
       "      <td>0.192529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>gpt</td>\n",
       "      <td>0.999414</td>\n",
       "      <td>0.242305</td>\n",
       "      <td>0.216128</td>\n",
       "      <td>0.242305</td>\n",
       "      <td>0.218852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.766699</td>\n",
       "      <td>0.232044</td>\n",
       "      <td>0.237683</td>\n",
       "      <td>0.232044</td>\n",
       "      <td>0.214954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>w2v</td>\n",
       "      <td>0.236328</td>\n",
       "      <td>0.250197</td>\n",
       "      <td>0.155866</td>\n",
       "      <td>0.250197</td>\n",
       "      <td>0.188198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>bert</td>\n",
       "      <td>0.401855</td>\n",
       "      <td>0.259669</td>\n",
       "      <td>0.248805</td>\n",
       "      <td>0.259669</td>\n",
       "      <td>0.238580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>gpt</td>\n",
       "      <td>0.220801</td>\n",
       "      <td>0.213102</td>\n",
       "      <td>0.090863</td>\n",
       "      <td>0.213102</td>\n",
       "      <td>0.113994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model   data  accuracy_is  \\\n",
       "0   RnnTextClassifier(\\n  (rnn): RNN(1000, 256, nu...  tfidf     0.985938   \n",
       "1   RnnTextClassifier(\\n  (rnn): RNN(1000, 256, nu...    w2v     0.237012   \n",
       "2   RnnTextClassifier(\\n  (rnn): RNN(768, 256, num...   bert     0.999414   \n",
       "3   RnnTextClassifier(\\n  (rnn): RNN(768, 256, num...    gpt     0.856934   \n",
       "4                   LogisticRegression(max_iter=4000)  tfidf     0.399902   \n",
       "5                   LogisticRegression(max_iter=4000)    w2v     0.239258   \n",
       "6                   LogisticRegression(max_iter=4000)   bert     0.405957   \n",
       "7                   LogisticRegression(max_iter=4000)    gpt     0.400098   \n",
       "8                            RandomForestClassifier()  tfidf     0.991211   \n",
       "9                            RandomForestClassifier()    w2v     0.999414   \n",
       "10                           RandomForestClassifier()   bert     0.999414   \n",
       "11                           RandomForestClassifier()    gpt     0.999414   \n",
       "12                                              SVC()  tfidf     0.766699   \n",
       "13                                              SVC()    w2v     0.236328   \n",
       "14                                              SVC()   bert     0.401855   \n",
       "15                                              SVC()    gpt     0.220801   \n",
       "\n",
       "    accuracy_oos  precision_oos  recall_oos    f1_oos  \n",
       "0       0.194159       0.196119    0.194159  0.194749  \n",
       "1       0.239148       0.195117    0.239148  0.173715  \n",
       "2       0.229676       0.230131    0.229676  0.228597  \n",
       "3       0.209945       0.201538    0.209945  0.192728  \n",
       "4       0.239148       0.232249    0.239148  0.231159  \n",
       "5       0.220205       0.193823    0.220205  0.184905  \n",
       "6       0.260458       0.261260    0.260458  0.258416  \n",
       "7       0.228098       0.225181    0.228098  0.219562  \n",
       "8       0.221784       0.220277    0.221784  0.215404  \n",
       "9       0.235201       0.226790    0.235201  0.227268  \n",
       "10      0.209945       0.193252    0.209945  0.192529  \n",
       "11      0.242305       0.216128    0.242305  0.218852  \n",
       "12      0.232044       0.237683    0.232044  0.214954  \n",
       "13      0.250197       0.155866    0.250197  0.188198  \n",
       "14      0.259669       0.248805    0.259669  0.238580  \n",
       "15      0.213102       0.090863    0.213102  0.113994  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuny",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
