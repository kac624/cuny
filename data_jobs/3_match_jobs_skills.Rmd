---
title: "DATA 607 - Project 3 - Matching jobs and skills"
author: "Keith Colella"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, message=FALSE}
library(tidyverse)
library(countrycode)
library(kableExtra)
```

## Introduction.

This work is the third of five stages of an analysis where the main objective was to identify the most valued data science skills. Our approach to this was to collect job postings from various job boards and extract the skills from the postings. The purpose of this specific file's work is to provide additional cleaning and synthesis of the data as well as to extract the skills from the job postings data.

## Additional cleaning and Mutating

First the files created from 2_create_clean_data_frames.Rmd were read in.  

```{r, warning=FALSE, message=FALSE}
job_listings <- read_csv('output/job_listings.csv')
skills <- read_csv('output/skills.csv')
```

Mutate was used to clean up and extract some additional variables. First, key columns (title, description, qualifications) were converted to lowercase and special characters were removed. The goal was to facilitate matches. Then, the highest education level requested in each listing was extracted, along with the max requested years of experience. A temporary "combo" field was created so that both job descriptions and qualifications fields could be easily reanalyzed. Also, the salary data was standardized into a common currency, USD.

```{r, warning=FALSE}
job_listings_enhanced <- job_listings %>%
  mutate(job_title = tolower(job_title) %>%
           str_replace_all('[â¢\u0080-\uFFFF]', ''),
         
         job_quals = tolower(job_quals) %>%
           str_replace_all('[â¢\u0080-\uFFFF]', '') %>%
           str_replace_all('[‘’“”\\,\\.\\(\\)\\;\\:\'\\?]','') %>%
           str_replace_all('[-]', ' '),
         
         job_description = tolower(job_description) %>%
           str_replace_all('[â¢\u0080-\uFFFF]', '') %>%
           str_replace_all('[‘’“”\\,\\.\\(\\)\\;\\:\'\\?]','') %>%
           str_replace_all('[-]', ' '),
         
         combo_details = str_c(job_quals, job_description),
         
         highest_ed = case_when(str_detect(combo_details, '(phd|ph d)') ~ 'phd',
                                str_detect(combo_details, 'master') ~ 'master',
                                str_detect(combo_details, 'advanced degree') ~ 'master',
                                str_detect(combo_details, 'bachelor') ~ 'bachelor'),
         
         years_exp = suppressWarnings({
           str_extract_all(combo_details, 
                           paste0('[0-9]{1,2}(?=(.){0,2}',
                                  '\\s+(\\b[a-z]+\\b\\s+){0,3}(years|year)',
                                  '\\s+(\\b[a-z]+\\b\\s+){0,3}experience)')) %>%
             map(as.numeric) %>%
             map(~ifelse(.x >= 20, 0, .x)) %>%
             map_dbl(max) %>%
             ifelse( (. == -Inf | . == 0), NA, .)
           }),
         
         continent = case_when(str_detect(location, '[A-Z]{2}') ~ 'Americas',
                               location == 'Remote' ~ 'Remote',
                               TRUE ~ countrycode(sourcevar = location,
                                                  origin = 'country.name',
                                                  destination = 'continent')),
         country = case_when(str_detect(location, '[A-Z]{2}') ~ 'United States',
                             TRUE ~ location),
         
         salary_min = case_when(salary_currency == 'GBP' ~ salary_min * 1.21,
                                salary_currency == 'EUR' ~ salary_min * 1.06,
                                TRUE ~ salary_min),
         salary_max = case_when(salary_currency == 'GBP' ~ salary_max * 1.21,
                                salary_currency == 'EUR' ~ salary_max * 1.06,
                                TRUE ~ salary_max),
         salary_currency = case_when(salary_currency == 'GBP' ~ 'USD',
                                     salary_currency == 'EUR' ~ 'USD',
                                     TRUE ~ salary_currency)
         
         ) %>%
  select(-combo_details)
```

## Skills Extraction

Next, all relevant skills from the qualifications and descriptions fields were extracted. These skills are first extracted into a list-column, with each row containing a list of unique skills mentioned in the job details. Then they are unnested to create another long-form dataframe to facilitate further analysis. This dataframe was joined to the initial skills dataframe by the `serch_word` to get all of the listed skills with proper capitalization. There was one job listing that was removed, as it was listed in German and there were no skills extracted due to the difference in language. 

```{r}
skills_clean <- skills$search_word %>%
  sort(decreasing = TRUE)

skill_regex_pattern <- paste0('\\b', paste(skills_clean, collapse = '\\b|\\b'), '\\b') %>%
  str_replace_all('c\\+\\+\\\\b','c\\\\\\+\\\\\\+\\(\\?\\= \\)') %>%
  str_replace_all('c#\\\\b','c\\\\\\#\\(\\?\\= \\)') %>%
  str_replace_all('visual\\\\b', '\\\\bvisual') %>%
  str_replace_all('collabor\\\\b', '\\\\bcollabor') %>%
  str_replace_all('communicat\\\\b', '\\\\bcommunicat')

job_listings_skills <- job_listings_enhanced %>%
  mutate(combo_details = str_c(job_quals, job_description),
         skills = str_extract_all(combo_details, skill_regex_pattern)) %>%
  select(-combo_details, -job_quals, -job_description) %>%
  rowwise() %>%
  mutate(skills = list(unique(skills))) %>%
  ungroup()

# combines the skills with the proper capitalization
# removes redundancies
job_listings_skills_long <- job_listings_skills %>%
  unnest_longer(col = skills, values_to = 'search_word', indices_include = FALSE) %>%
  right_join(skills, by = "search_word") %>%
  select(-search_word) %>%
  filter(!is.na(website)) %>%
  unique()

job_id_and_skills <- job_listings_skills_long %>%
  group_by(job_id) %>%
  mutate(skills = list(skill)) %>%
  transmute(job_id, skills) %>%
  unique()

# removing German job listing - no skills extracted 
# adding skills string with proper capitalization 
job_listings_skills <- job_listings_skills %>%
  filter(job_id %in% job_id_and_skills$job_id) %>%
  mutate(skills = job_id_and_skills$skills)

job_listings_skills_string <- job_listings_skills %>%
  rowwise() %>% 
  mutate(skills = paste(unlist(skills), collapse=', ')) %>%
  ungroup()
```

```{r eval=FALSE, echo=FALSE}
test <- job_listings_enhanced %>% filter(job_id == 41765)

job_listings_skills_test <- test %>%
  mutate(combo_details = str_c(job_quals, job_description),
         skills = str_extract_all(combo_details, skill_regex_pattern))# %>% '\\bc\\+\\+ \\b'

job_listings_skills_test$skills
```

### Function for Extracting Skills

Another method we tried for extracting skills is shown in the function below. `extractSkills` was created to cross check the skills dictionary against the job descriptions from the job listings. Within the function,  `job_quals` and `job_description` were checked to account for all places where there might be any skills listed. Ultimately, this function was not used but it is included to show an alternative way for skills extraction to occur. 

```{r skills-extract-func, eval=FALSE}
extractSkills <- function(job_df, dict) {
  job_id_and_skill <- c()
  
  # checking for R (programming language) or broader language use
  vis_and_r_check <- c("R"="(\\s|\\\\)R(\\s|,|\\\\)", 
                       "Data visualization"="visual", 
                       "Data collection" = "(Data collection|collect data)", 
                       "Data analysis" = "(Data analysis|analyze data)", 
                       "Communication" = "(Communication|communicate)", 
                       "Collaboration" = "(Collaboration|collaborate|collaborative)", 
                       "C" = "(\\s|\\\\)C(\\s|,|\\\\)", "C\\+\\+" = "C\\\\+\\\\+")

  for(i in 1:length(job_df$job_id)) {
    job_id <- job_df$job_id[i]
    search <- paste(job_df$job_quals[i], job_df$job_desciption[i])
  
    for (j in 1:length(dict)) {
      pat <- dict[j]
      
      if (!pat %in% names(vis_and_r_check)) {
        if (str_detect(tolower(search), tolower(pat))) {
        job_id_and_skill <- append(job_id_and_skill, paste(job_id, pat, sep = ","))
        }
      } else {
        new_pat <- vis_and_r_check[pat]
      
        if (str_detect(tolower(search), tolower(new_pat))) {
        job_id_and_skill <- append(job_id_and_skill, paste(job_id, pat, sep = ","))
        }
      }
    }
  }

  skills_df <- data.frame("job_id_and_skill" = job_id_and_skill) %>%
    separate(col = job_id_and_skill, into = c("job_id", "skill"), sep = ",")
  
  return(skills_df)
}
```

To take a quick look at the cleaned data from each source the below code could be uncommented. 

```{r}
# for (source in unique(job_listings_skills_string$website)) {
#   tbl <- job_listings_skills_string %>%
#     filter(website == source,
#            !is.na(highest_ed),
#            !is.na(years_exp)) %>%
#     head(5) %>%
#     print()
# }
# 
# for (source in unique(job_listings_skills_long$website)) {
#   tbl <- job_listings_skills_long %>%
#     filter(website == source,
#            !is.na(highest_ed),
#            !is.na(years_exp)) %>%
#     head(15) %>%
#     print()
# }
```

A look at the dataframe created is below.

```{r}
kable(head(job_listings_skills_long,5))  |>
  kable_styling("striped")
```


## Save the Dataframes as CSV

The dataframes were written to csv files.

```{r}
write.csv(job_listings_enhanced, "output/job_listings_enhanced.csv", row.names = FALSE)
write.csv(job_listings_skills_long, "output/job_listings_skills_long.csv", row.names = FALSE)
write.csv(job_listings_skills_string, "output/job_listings_skills_string.csv", row.names = FALSE)
write.csv(job_listings_skills_string, "job_recommendations/job_listings_skills_string.csv", row.names = FALSE)
```

## Conclusion

The objective of this stage of the analysis was met, the skills were successfully extracted from the job qualifications and descriptions. One limitation of this work is the length of time that it takes for the skills extraction to be done. For a future extension of this work, if more job postings are aggregated and more skills added - the processing time could become unreasonably long - a process to speed up skills extraction would need to be explored. 
