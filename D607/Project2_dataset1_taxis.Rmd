---
title: "Project 2 - Dataset 1"
author: "Keith Colella"
date: "`r Sys.Date()`"
output: html_document
knit: (function(input, ...) {
    rmarkdown::render(
      input,
      output_dir = "../D607/output"
    )
  })
---

```{r setup, message=FALSE}
library(tidyverse)
library(arrow)
library(lubridate)
library(sf)
```

## Reading in Data

I'll focus on a massive dataset detailing all taxis rides in New York City since 2009. The data is maintained by the NYC government at the following site.

https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page

The data are maintained in a series of many files, broken out month year, month and taxi type (e.g. yellow, green, rideshare). I'll begin by reading in a single file to get a sense of the data. The data is stored in .parquet format, so I'll need the `arrow` package's `read_parquet` function.

```{r}
pq_file <- tempfile()
url <- paste0('https://d37ci6vzurychx.cloudfront.net/',
              'trip-data/fhv_tripdata_2011-01.parquet')

download.file(url, pq_file, mode = 'wb')

df <- read_parquet(pq_file, as_data_frame = TRUE)

head(df)

colnames(df) <- tolower(colnames(df)) %>%
        str_replace_all('.*pickup_date.*','pickup_date') %>%
        str_replace_all('total_am.*','total_amount') %>%
        str_replace_all('.*p.*location.*','pickup_location') %>%
        str_replace_all('.*d.*location.*','dropoff_location')

df <- df %>%
        mutate(year = year(pickup_date),
               month = month(pickup_date),
               pickup_location = replace_na(pickup_location,0),
               dropoff_location = replace_na(dropoff_location,0)) %>%
        filter(year == 2010 &
                 month == 1)

aggr_data1 <- df %>%
  group_by(year, month, pickup_location) %>%
  summarize(pickups = n(), .groups = 'keep')

aggr_data2 <- df %>%
  group_by(year, month, dropoff_location) %>%
  summarize(dropoffs = n(), .groups = 'keep')

holder <- data.frame(year = 2022,
                     month = rep(1:12, each = 265),
                     location = seq(1:265))
  
holder %>%
  left_join(aggr_data1, by = c('year','month','location' = 'pickup_location')) %>%
  left_join(aggr_data2, by = c('year','month','location' = 'dropoff_location'))
```

It looks like we're dealing with a LOT of data. I'll put together a quick summary to see how many rides we're looking at.

```{r}
df %>%
  filter(year(tpep_pickup_datetime) != 2022 | month(tpep_pickup_datetime) != 1) %>%
  group_by(date(tpep_pickup_datetime)) %>%
  summarize(ride_count = n())
```

For single taxi type in a single month, we have ###### individual observations. So, it seems like we'll need to do some aggregation. Moreover, even though this file is meant to captured only January 2022, there appear to be some observations from other years and months. Given that I plan to aggregate by month and year, I'll need to perform some cleaning on each files.

I also notice that files for all taxi types are not available back to 2009. Green taxis were introduced in 2013, and for-hire vehicles (which refers to private rideshare cabs like Uber and Lyft) were not tracked until 2015 (originally under "fhv" and then split into high and low volume categories, represented as "fhvhv" and "fhv", respectively).

After performing the above exploration on files from for each taxi type and across several years, it became clear that the file format has also changed a few times over the years. While I'd like to analyze costs and volume of passengers, those variables appear inconsistently across the data. The variables that appear most consistently are date-time and pickup/dropoff location. So, I'll plan to focus on the total volume of rides across time and geography.

Considering all of the above, I constructed the below function to pull and aggregate data. The function requires a specific taxi type, a starting year and an ending year. It reads through all files matching these input parameters and aggregates the volume of rides, broken out by year, month and dropoff location. Error handling accounts for missing files, and progress is tracked in a distinct progress dataframe.

```{r}
pull_taxi_data_aggr <- function(taxi_type, start_year, end_year, quiet = FALSE) {
  aggregated_df <- data.frame(matrix(nrow = 0, ncol = 0))
  process_summary <- data.frame(matrix(nrow = 0, ncol = 0))
  
  for (yr in start_year:end_year) {
    for (mnth in 1:12) {
      # attempt file download
      time_check <- now()
      year_month <- paste0(yr,'-',sprintf('%02d',mnth))
      pq_file <- tempfile()
      url <- paste0('https://d37ci6vzurychx.cloudfront.net/trip-data/',
                    taxi_type,'_tripdata_',year_month,'.parquet')
      suppressWarnings({
        test <- tryCatch(download.file(url, pq_file, mode = 'wb', quiet = TRUE), 
                         error = function(e) e)
      })
      if('error' %in% class(test)) {
        progress <- data.frame(year_month, file_size = NA, time_check)
        process_summary <- bind_rows(process_summary, progress)
        next
      }
      
      # mark progress
      file_size <- file.size(pq_file) / 10^6
      progress <- data.frame(year_month, file_size , time_check)
      process_summary <- bind_rows(process_summary, progress)
      if (quiet == FALSE) {
       print(paste0('Progress  --  ',
                           'File: ',year_month,'  --  ',
                           'Size: ',file_size,'MB  --  ',
                           'Time: ',time_check)) 
      }
      
      # read to df and clean    
      pq_data <- read_parquet(pq_file, as_data_frame = TRUE)
      colnames(pq_data) <- tolower(colnames(pq_data)) %>%
        str_replace_all('.*pickup_date.*','pickup_date') %>%
        str_replace_all('total_am.*','total_amount') %>%
        str_replace_all('.*p.*location.*','pickup_location') %>%
        str_replace_all('.*d.*location.*','dropoff_location')
      
      pq_data <- pq_data %>%
        mutate(year = year(pickup_date),
               month = month(pickup_date),
               pickup_location = replace_na(pickup_location,0),
               dropoff_location = replace_na(dropoff_location,0)) %>%
        filter(year == yr &
                 month == mnth)
      
      #aggregate and add to collection df
      pickup_data <- pq_data %>%
        group_by(year, month, pickup_location) %>%
        summarize(pickups = n(), .groups = 'keep')
      
      dropoff_data <- pq_data %>%
        group_by(year, month, dropoff_location) %>%
        summarize(dropoffs = n(), .groups = 'keep')
      
      aggr_data <- data.frame(year = yr,
                                  month = mnth,
                                  location = seq(from = 0, to = 265)) %>%
        left_join(pickup_data, by = c('year','month','location' = 'pickup_location')) %>%
        left_join(dropoff_data, by = c('year','month','location' = 'dropoff_location'))
      
      aggregated_df <- bind_rows(aggregated_df, aggr_data)
      file.remove(pq_file)
    }
  }
  aggregated_df <- aggregated_df %>% mutate(type = taxi_type)
  process_summary <- process_summary %>% mutate(type = taxi_type)
  return(list(aggregated_df, 
              process_summary))
}
```

We then use this function in a loop to grab data for all four taxi types from 2009 to 2020. I'll kick this off and let it run.

```{r}
greens <- pull_taxi_data_aggr(taxi_type = 'green', 
                             start_year = 2013,
                             end_year = 2022,
                             quiet = FALSE)

fhvs <- pull_taxi_data_aggr(taxi_type = 'fhv', 
                           start_year = 2015,
                           end_year = 2022,
                           quiet = FALSE)

fhvhvs <- pull_taxi_data_aggr(taxi_type = 'fhvhv', 
                             start_year = 2019,
                             end_year = 2022,
                             quiet = FALSE)

yellows <- pull_taxi_data_aggr(taxi_type = 'yellow', 
                             start_year = 2011,
                             end_year = 2022,
                             quiet = FALSE)
```



```{r}
aggregated_df_all <- bind_rows(greens[[1]],
                               fhvs[[1]],
                               fhvhvs[[1]],
                               yellows[[1]])

full_process_summary <-  bind_rows(greens[[2]],
                                   fhvs[[2]],
                                   fhvhvs[[2]],
                                   yellows[[2]])
```



```{r}
filter(aggregated_df_all, is.na(pickups) & is.na(dropoffs)) %>%
  arrange(type, year, month, location)

filter(full_process_summary, is.na(file_size))

aggregated_df_all %>%
  group_by(year, type) %>%
  summarize(pickups_total = sum(pickups, na.rm = TRUE),
            dropoffs_total = sum(dropoffs, na.rm = TRUE),
            .groups = 'keep')

aggregated_df_all %>%
  group_by(location) %>%
  summarize(pickups_total = sum(pickups, na.rm = TRUE),
            dropoffs_total = sum(dropoffs, na.rm = TRUE),
            .groups = 'keep')
```



```{r}
write_csv(aggregated_df_all, 'output/aggregated_taxi_data.csv')
write_csv(full_process_summary, 'output/taxi_process_summary.csv')
```


## TBD

TBD

```{r}
aggregated_df_all_2  <- aggregated_df_all %>%
  mutate(date = ymd(paste0(year,'-',sprintf('%02d',month),'-01')),
         type = case_when(type == 'yellow' ~ 'yellow',
                          type == 'green' ~ 'green',
                          type == 'fhv' | type == 'fhvhv' ~ 'rideshare')) %>%
  group_by(date, location, type) %>%
  summarize(pickups = sum(pickups, na.rm = TRUE), 
            dropoffs = sum(dropoffs, na.rm = TRUE),
            .groups = 'keep')
```



```{r}
aggregated_df_all_2 %>%
  group_by(date, type) %>%
  summarize(pickups = sum(pickups, na.rm = TRUE), 
            dropoffs = sum(dropoffs, na.rm = TRUE),
            .groups = 'keep') %>%
  ggplot(aes(x = date, y = pickups, fill = type)) + 
  geom_area() +
  scale_fill_manual(values = c('darkolivegreen3','deepskyblue3','gold3')) +
  scale_y_continuous(labels = scales::comma)
```



```{r}
pq_file <- tempfile()
url <- paste0('https://d37ci6vzurychx.cloudfront.net/',
              'trip-data/fhv_tripdata_2011-01.parquet')
download.file(url, pq_file, mode = 'wb')
shapes <- read_parquet(pq_file, as_data_frame = TRUE)
```



```{r}
aggregated_df_all_2 %>%
  group_by(date, type) %>%
  summarize(pickups = sum(pickups, na.rm = TRUE), 
            dropoffs = sum(dropoffs, na.rm = TRUE),
            .groups = 'keep') %>%
  ggplot(aes(x = date, y = pickups, fill = type)) + 
  geom_area() +
  scale_fill_manual(values = c('darkolivegreen3','deepskyblue3','gold3')) +
  scale_y_continuous(labels = scales::comma)
```