---
title: "Project4"
author: "Keith Colella"
date: "`r Sys.Date()`"
output: html_document
knit: (function(input, ...) {
    rmarkdown::render(
      input,
      output_dir = "../D607/output"
    )
  })
---

```{r setup, message = FALSE}
library(tidyverse)
library(httr)
library(jsonlite)
library(fuzzyjoin)
```

## Initial Universe of Candidates

https://api.open.fec.gov/developers/
https://github.com/stephenholzman/tidyusafec

```{r}
year = 2022
fec_key <- read_lines('data/fec_api.txt')

query_params <- list(election_year = year,
                     office = 'H',
                     api_key = fec_key)
url <- modify_url('https://api.open.fec.gov/', 
                  path = '/v1/candidates/search/',
                  query = query_params)

initial_response <- GET(url)
parsed_response <- fromJSON(content(initial_response, "text", encoding="UTF-8"), 
                            simplifyVector = FALSE)
total_pages <- parsed_response$pagination$pages
```

Loop through pages to get total responses

```{r}
response <- list()

for (i in 1:total_pages) {
  query_params <- list(page = i,
                       election_year = year,
                       office = 'H',
                       api_key = fec_key)
  url <- modify_url('https://api.open.fec.gov/', 
                    path = '/v1/candidates/search/',
                    query = query_params)
  initial_response <- GET(url)
  parsed_response <- fromJSON(content(initial_response, 'text', encoding='UTF-8'), 
                              simplifyVector = FALSE)
  response[[i]] <- parsed_response
  Sys.sleep(0.5)
}
```

Loop through responses and grab individual observations

```{r}
candidates <- map(response, function(x) x$results) %>%
    unlist(recursive = F) %>%
    tibble(
      fec_id = map_chr(., 'candidate_id', .default = NA),
      name = map_chr(., 'name', .default = NA),
      state = map_chr(., 'state', .default = NA),
      district = map_chr(., 'district', .default = NA),
      party = map_chr(., 'party_full', .default = NA),
      office = map_chr(., 'office_full', .default = NA),
      incumbent_challenge = map_chr(., 'incumbent_challenge_full', .default = NA),
      candidate_status = map_chr(., 'candidate_status', .default = NA),
    ) %>%
  select(-.)

candidates %>% head()
```

## Twitter IDs for candidates

https://github.com/unitedstates/congress-legislators
https://ballotpedia.org/List_of_congressional_candidates_in_the_2022_elections
https://www.propublica.org/datastore/dataset/politicians-tracked-by-politwoops

```{r, message = FALSE}
congress_current <- read_csv('https://theunitedstates.io/congress-legislators/legislators-current.csv')
congress_history <- read_csv('https://theunitedstates.io/congress-legislators/legislators-historical.csv')

congress <- rbind(congress_current, congress_history)

ballotpedia <- read_csv('data/ballotpedia_scrape2022.csv')

poliwoops = read_csv('https://s3.amazonaws.com/pp-projects-static/politwoops/active_accounts.csv')
```

https://www.rdocumentation.org/packages/stringdist/versions/0.9.10/topics/stringdist-metrics

```{r}
for (i in colnames(ballotpedia)) {
  ballotpedia[is.na(ballotpedia[i]), ] %>%
    print()
}

ballotpedia$party_simple %>% unique()

og_candidates <- candidates
og_ballotpedia <- ballotpedia
```


```{r}
candidates <- og_candidates
ballotpedia <- og_ballotpedia

candidates[is.na(candidates)] <- ''
ballotpedia[is.na(ballotpedia)] <- ''

candidates <- candidates %>%
  mutate(party_simple = case_when(party == 'REPUBLICAN PARTY' ~ 'Republican',
                                  party == 'DEMOCRATIC PARTY' ~ 'Democrat',
                                  TRUE ~ 'Other'),
         last_name = str_extract(candidates$name, '.*(?=,)'),
         first_name = str_extract(candidates$name, '(?<=, ).*'),
         name = str_c(first_name, ' ',last_name)) %>%
  replace(is.na(.), '') %>%
  # mutate(key = str_c(state, party_simple, 
  #                    str_replace_all(name, fixed(' '), '')) %>%
  #          tolower() %>% trimws() %>% 
  #          str_remove_all('[[:punct:]]'))
  mutate(key = str_remove_all(name, fixed(' ')) %>%
           str_remove_all('[[:punct:]]') %>%
           tolower() %>% trimws()) %>%
  select(-last_name, -first_name)

ballotpedia <- ballotpedia %>%
  mutate(state = state.abb[match(state,state.name)],
         party_simple = case_when(party == 'Republican Party' ~ 'Republican',
                                  party == 'Democratic Party' ~ 'Democrat',
                                  TRUE ~ 'Other')) %>%
  replace(is.na(.), '') %>%
  # mutate(key = str_c(state, party_simple, 
  #                    str_replace_all(name, fixed(' '), '')) %>%
  #          tolower() %>% trimws() %>% 
  #          str_remove_all('[[:punct:]]'))
  mutate(key = str_remove_all(name, fixed(' ')) %>%
           str_remove_all('[[:punct:]]') %>%
           tolower() %>% trimws())

# candidates
# ballotpedia
# 
# candidates[candidates$key == 'ut republican tim aalders', ]
# ballotpedia[ballotpedia$key == 'ut republican timothy noel aalders', ]
# 
# candidates %>%
#   left_join(
#     ballotpedia %>%
#       select(twitter, ballotpedia, key),
#     by = 'key', suffix = c('.x', '.y'),
#     keep = TRUE) %>%
#   select(key.x, key.y, twitter, party, state)

# candidates %>%
#   ## Fuzzy join to grab twitter handles from ballotpedia
#   stringdist_join(
#     select(ballotpedia, twitter, state, party_simple),
#     by = 'key',
#     mode = 'inner',
#     method = 'lv',
#     max_dist = 5,
#     ignore_case = TRUE,
#     distance_col = 'distance') %>%
#   select(key.x, key.y, distance, state, party_simple)

candidates %>%
  ## Fuzzy join to grab twitter handles from ballotpedia
  stringdist_join(
    select(ballotpedia, key, state, party_simple),
    by = 'key',
    mode = 'inner',
    method = 'lv',
    max_dist = 4,
    ignore_case = TRUE,
    distance_col = 'distance') %>%
  filter(state.x == state.y, 
         party_simple.x == party_simple.y) %>%
  select(key.x, key.y, distance, 
         state.x, state.y, 
         party_simple.x, party_simple.y)
```

Join

```{r}
candidates_twitter <- candidates %>%
  ## Join with IDs from congress data
  left_join(
    select(congress, twitter_id, bioguide_id, fec_ids),
    by = c('fec_id' = 'fec_ids'), suffix = c('','_congress'), keep = FALSE) %>%
  ## Join with IDs from poliwoops data based on bioguide ID
  left_join(
    select(poliwoops, twitter_id, bioguide_id) %>%
      filter(!is.na(bioguide_id)),
    by = 'bioguide_id', suffix = c('','_poliw_bio'), keep = FALSE) %>%
  ## Join with IDs from poliwoops data based on fec ID
  left_join(
    select(poliwoops, twitter_id, fec_candidate_id) %>%
      filter(!is.na(fec_candidate_id)), 
    by = c('fec_id' = 'fec_candidate_id'), suffix = c('','_poliw_fec'), keep = FALSE)%>%
  ## Fill in twitter_id col to allow filtering
  mutate(twitter_id = case_when(
    !is.na(twitter_id) ~ twitter_id,
    !is.na(twitter_id_poliw_fec) ~ twitter_id_poliw_fec,
    !is.na(twitter_id_poliw_bio) ~ twitter_id_poliw_bio)) %>%
  filter(!is.na(twitter_id)) %>%
  ## Convert IDs to list, then unnest to long format
  unite(twitter_id, twitter_id, twitter_id_poliw_fec, twitter_id_poliw_bio, 
        sep = ',', na.rm = TRUE) %>% 
  mutate(twitter_id = str_split(as.character(twitter_id), ",")) %>%
  unnest(twitter_id)

## Remove dupes
candidates_twitter <- candidates_twitter[!duplicated(candidates_twitter), ]

candidates_twitter
```


```{r}
write_csv(candidates_twitter, paste0('data/candidates',year,'.csv'))
```


